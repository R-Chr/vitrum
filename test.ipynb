{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ase\n",
    "from ase import io\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import dionysus\n",
    "import diode\n",
    "from scipy.signal import argrelextrema\n",
    "import math\n",
    "from ase import Atoms\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import Birch\n",
    "from sklearn.neighbors import KernelDensity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class glass_Atoms(Atoms):\n",
    "    # def __init__(self):\n",
    "    #    super().__init__()\n",
    "\n",
    "    def get_dist(self):\n",
    "        dim = np.diagonal(self.get_cell())\n",
    "        positions = self.get_positions()\n",
    "        x_dif = np.abs(positions[:, 0][np.newaxis, :] - positions[:, 0][:, np.newaxis])\n",
    "        y_dif = np.abs(positions[:, 1][np.newaxis, :] - positions[:, 1][:, np.newaxis])\n",
    "        z_dif = np.abs(positions[:, 2][np.newaxis, :] - positions[:, 2][:, np.newaxis])\n",
    "        x_dif = np.where(x_dif > 0.5 * dim[0], np.abs(x_dif - dim[0]), x_dif)\n",
    "        y_dif = np.where(y_dif > 0.5 * dim[1], np.abs(y_dif - dim[1]), y_dif)\n",
    "        z_dif = np.where(z_dif > 0.5 * dim[2], np.abs(z_dif - dim[2]), z_dif)\n",
    "        i_i = np.sqrt(x_dif**2 + y_dif**2 + z_dif**2)\n",
    "        return i_i\n",
    "\n",
    "    def set_new_chemical_symbols(self, dict):\n",
    "        corr_symbols= [dict[i] for i in self.get_atomic_numbers()]\n",
    "        atomic_numbers = self.set_chemical_symbols(corr_symbols)\n",
    "\n",
    "    def get_pdf(self, target_atoms, rrange=10, nbin=100):\n",
    "        if isinstance(target_atoms[0], str):\n",
    "            types = self.get_chemical_symbols()\n",
    "        if isinstance(target_atoms[0], int):\n",
    "            types = self.get_atomic_numbers()\n",
    "        types = np.array(types)\n",
    "        distances = self.get_dist()\n",
    "        atom_1 = np.where(types == target_atoms[0])[0]\n",
    "        atom_2 = np.where(types == target_atoms[1])[0]\n",
    "        dist_list = distances[np.ix_(atom_1, atom_2)]\n",
    "        edges = np.linspace(0, rrange, nbin + 1)\n",
    "        xval = edges[1:] - 0.5 * (rrange / nbin)\n",
    "        volbin = []\n",
    "        for i in range(nbin):\n",
    "            vol = ((4 / 3) * np.pi * (edges[i + 1]) ** 3) - (\n",
    "                (4 / 3) * np.pi * (edges[i]) ** 3\n",
    "            )\n",
    "            volbin.append(vol)\n",
    "\n",
    "        h, bin_edges = np.histogram(dist_list, bins=nbin, range=(0, rrange))\n",
    "        h[0] = 0\n",
    "        pdf = (h / volbin) / (\n",
    "            dist_list.shape[0] * dist_list.shape[1] / self.get_volume()\n",
    "        )\n",
    "        return xval, pdf\n",
    "\n",
    "    def get_persistence_diagram(self, dimension=1, weights=None):\n",
    "        coord = self.get_positions()\n",
    "        data = np.column_stack([self.get_chemical_symbols(), coord])\n",
    "        dfpoints = pd.DataFrame(data, columns=[\"Atom\", \"x\", \"y\", \"z\"])\n",
    "        chem_species = np.unique(self.get_chemical_symbols())\n",
    "\n",
    "        if weights is None:\n",
    "            radii = [0 for i in chem_species]\n",
    "        elif isinstance(weights, dict):\n",
    "            radii = [weights[i] for i in chem_species]\n",
    "        elif isinstance(weights, list):\n",
    "            radii = weights\n",
    "\n",
    "        conditions = [(dfpoints[\"Atom\"] == i) for i in chem_species]\n",
    "        choice_weight = [i**2 for i in radii]\n",
    "\n",
    "        dfpoints[\"w\"] = np.select(conditions, choice_weight)\n",
    "        dfpoints[\"x\"] = pd.to_numeric(dfpoints[\"x\"])\n",
    "        dfpoints[\"y\"] = pd.to_numeric(dfpoints[\"y\"])\n",
    "        dfpoints[\"z\"] = pd.to_numeric(dfpoints[\"z\"])\n",
    "\n",
    "        points = dfpoints[[\"x\", \"y\", \"z\", \"w\"]].to_numpy()\n",
    "        simplices = diode.fill_weighted_alpha_shapes(points)\n",
    "        f = dionysus.Filtration(simplices)\n",
    "        m = dionysus.homology_persistence(f)\n",
    "        dgms = dionysus.init_diagrams(m, f)\n",
    "\n",
    "        # Gather the PD of loop in a dataframe\n",
    "        dfPD = pd.DataFrame(\n",
    "            data={\n",
    "                \"Birth\": [p.birth for p in dgms[dimension]],\n",
    "                \"Death\": [p.death for p in dgms[dimension]],\n",
    "            }\n",
    "        )\n",
    "        return dfPD\n",
    "\n",
    "    def get_local_persistence(self, center_id, cutoff):\n",
    "        persistence_diagrams = []\n",
    "        if isinstance(center_id, str):\n",
    "            types = self.get_chemical_symbols()\n",
    "        if isinstance(center_id, int):\n",
    "            types = self.get_atomic_numbers()\n",
    "        centers = np.where(types == center_id)[0]\n",
    "        for i in centers:\n",
    "            neighbors = np.where(self.get_dist()[i, :] < cutoff)[0]\n",
    "            neighborhood = self[neighbors]\n",
    "            neighborhood.center()\n",
    "            persistence_diagrams.append(neighborhood.get_persistence_diagram())\n",
    "        return persistence_diagrams\n",
    "\n",
    "    def get_angular_dist(self, center_type, neigh_type, cutoff=\"Auto\"):\n",
    "        distances = self.get_dist()\n",
    "\n",
    "        types = self.get_chemical_symbols()\n",
    "        center_index = np.where(types == center_type)[0]\n",
    "        neigh_index = np.where(types == neigh_type)[0]\n",
    "\n",
    "        if cutoff == \"Auto\":\n",
    "            pdf = self.get_pdf(target_atoms=[center_type, neigh_type])\n",
    "            cutoff = pdf[0][self.find_min_after_peak(pdf[1])]\n",
    "        elif isinstance(cutoff, float | int):\n",
    "            cutoff = cutoff\n",
    "\n",
    "        angles = []\n",
    "\n",
    "        for center in center_index:\n",
    "            neighbors = np.where(\n",
    "                (distances[neigh_index, center] < cutoff)\n",
    "                & (distances[neigh_index, center] > 0)\n",
    "            )[0]\n",
    "            if neighbors.shape[0] < 2:\n",
    "                continue\n",
    "            upper_index = np.triu_indices(neighbors.shape[0], k=1)\n",
    "            comb_1 = np.meshgrid(neighbors, neighbors)[0][upper_index]\n",
    "            comb_2 = np.meshgrid(neighbors, neighbors)[1][upper_index]\n",
    "            indicies = np.vstack(\n",
    "                (neigh_index[comb_1], np.full(len(comb_1), center), neigh_index[comb_2])\n",
    "            ).T\n",
    "            angles.append(self.get_angles(indicies, mic=True))\n",
    "        return angles\n",
    "\n",
    "    def get_coordination_number(self, center_type, neigh_type, cutoff=\"Auto\"):\n",
    "        distances = self.get_dist()\n",
    "        types = self.get_chemical_symbols()\n",
    "        atom_1 = np.where(types == center_type)[0]\n",
    "        atom_2 = np.where(types == neigh_type)[0]\n",
    "        dist_list = distances[np.ix_(atom_1, atom_2)]\n",
    "\n",
    "        if cutoff == \"Auto\":\n",
    "            pdf = self.get_pdf(target_atoms=[center_type, neigh_type])\n",
    "            cutoff = pdf[0][self.find_min_after_peak(pdf[1])]\n",
    "        elif isinstance(cutoff, float | int):\n",
    "            cutoff = cutoff\n",
    "        print(cutoff)\n",
    "        coordination_numbers = []\n",
    "        for center in range(len(atom_1)):\n",
    "            neighbors = np.where(\n",
    "                (dist_list[center, :] < cutoff) & (dist_list[center, :] > 0)\n",
    "            )[0]\n",
    "            coordination_numbers.append(neighbors.shape[0])\n",
    "        return coordination_numbers\n",
    "\n",
    "    def find_min_after_peak(self, padf):\n",
    "        mins = argrelextrema(padf, np.less_equal, order=4)[0]\n",
    "        second_min = [i for ind, i in enumerate(mins) if i != ind][0]\n",
    "        return second_min\n",
    "\n",
    "    def NBO_analysis(distances, center_index, neigh_index_1, neigh_index_2, cutoffs):\n",
    "        P_neigh_unique = []\n",
    "        for center in center_index:\n",
    "            neighbors = np.where(\n",
    "                (distances[neigh_index, center] < cutoff[0])\n",
    "                & (distances[neigh_index, center] > 0)\n",
    "            )[0]\n",
    "            P_neigh_unique.append([O_ind[neigh] for neigh in neighbors])\n",
    "        P_neigh_unique = np.unique(np.hstack(P_neigh_unique))\n",
    "\n",
    "        bond_order = [0, 0, 0, 0]\n",
    "        for neigh in P_neigh_unique:\n",
    "            neighbor_list_1 = np.where(\n",
    "                (distances[neigh_index_1, neigh] < cutoff[0])\n",
    "                & (distances[neigh_index_1, neigh] > 0)\n",
    "            )[0]\n",
    "            neighbor_list_2 = np.where(\n",
    "                (distances[neigh_index_2, neigh] < cutoff[1])\n",
    "                & (distances[neigh_index_2, neigh] > 0)\n",
    "            )[0]\n",
    "\n",
    "            if neighbor_list_P.shape[0] + neighbor_list_Fe.shape[0] == 1:\n",
    "                bond_order[0] += 1\n",
    "            elif neighbor_list_P.shape[0] + neighbor_list_Fe.shape[0] == 2:\n",
    "                bond_order[1] += 1\n",
    "            elif neighbor_list_P.shape[0] + neighbor_list_Fe.shape[0] == 3:\n",
    "                bond_order[2] += 1\n",
    "            elif neighbor_list_P.shape[0] + neighbor_list_Fe.shape[0] == 0:\n",
    "                bond_order[3] += 1\n",
    "        return coordination_number\n",
    "\n",
    "    def get_total_rdf(self, nbin=100, rrange=10):\n",
    "        scattering_lengths = pd.read_csv(\"scattering_lengths.csv\", sep=\";\", decimal=\",\")\n",
    "        chemical_symbols = self.get_chemical_symbols()\n",
    "        species = np.unique(chemical_symbols)\n",
    "        b = np.array(\n",
    "            [\n",
    "                scattering_lengths[scattering_lengths[\"Isotope\"] == i][\"b\"]\n",
    "                for i in species\n",
    "            ]\n",
    "        ).flatten()\n",
    "        c = [chemical_symbols.count(i) / len(chemical_symbols) for i in species]\n",
    "        cb = [i * j for i, j in zip(c, b)]\n",
    "        timesby = []\n",
    "        for pair in itertools.product(cb, repeat=2):\n",
    "            timesby.append(pair[0] * pair[1])\n",
    "        dividetot = sum(timesby)\n",
    "        cb_sum = (sum([i * j for i, j in zip(c, b)]) ** 2) / 100\n",
    "\n",
    "        gr_tot = np.zeros([nbin])\n",
    "        for ind, pair in enumerate(itertools.product(species, repeat=2)):\n",
    "            pdf = self.get_pdf(\n",
    "                target_atoms=[pair[0], pair[1]], rrange=rrange, nbin=nbin\n",
    "            )\n",
    "            gr_tot = gr_tot + (timesby[ind] * pdf[1]) / dividetot\n",
    "        return pdf[0], gr_tot\n",
    "\n",
    "    def get_partial_structure_factor(\n",
    "        self, target_atoms, qrange=30, nbin=100, rrange=10\n",
    "    ):\n",
    "        chemical_symbols = self.get_chemical_symbols()\n",
    "        species = np.unique(chemical_symbols)\n",
    "        aveden = np.mean(\n",
    "            [chemical_symbols.count(i) / self.get_volume() for i in species]\n",
    "        )\n",
    "        qval = np.linspace(0.5, qrange, nbin)\n",
    "        xval, pdf = self.get_pdf(target_atoms=target_atoms, rrange=rrange, nbin=nbin)\n",
    "        q_r = np.outer(qval, xval).T\n",
    "        q_r = np.sin(q_r) / q_r\n",
    "        A_q = (\n",
    "            4 * math.pi * xval**2 * (pdf - 1) * q_r\n",
    "        )  # *(np.sin(math.pi*xval/rrange)/(math.pi*xval/rrange))\n",
    "        A_q = 1 + aveden * np.trapz(A_q, xval)\n",
    "        return qval, A_q\n",
    "\n",
    "    def get_strucutre_factor(self, nbin=100):\n",
    "        scattering_lengths = pd.read_csv(\"scattering_lengths.csv\", sep=\";\", decimal=\",\")\n",
    "        chemical_symbols = self.get_chemical_symbols()\n",
    "        species = np.unique(chemical_symbols)\n",
    "        b = np.array(\n",
    "            [\n",
    "                scattering_lengths[scattering_lengths[\"Isotope\"] == i][\"b\"]\n",
    "                for i in species\n",
    "            ]\n",
    "        ).flatten()\n",
    "        c = [chemical_symbols.count(i) / len(chemical_symbols) for i in species]\n",
    "        cb = [i * j for i, j in zip(c, b)]\n",
    "        timesby = []\n",
    "        for pair in itertools.product(cb, repeat=2):\n",
    "            timesby.append(pair[0] * pair[1])\n",
    "        dividetot = sum(timesby)\n",
    "        cb_sum = (sum([i * j for i, j in zip(c, b)]) ** 2) / 100\n",
    "\n",
    "        S_q_tot = np.zeros(nbin)\n",
    "        for ind, pair in enumerate(itertools.product(species, repeat=2)):\n",
    "            qval, partial_sq = self.get_partial_structure_factor(\n",
    "                target_atoms=[pair[0], pair[1]], nbin=nbin\n",
    "            )\n",
    "            S_q_tot = S_q_tot + (timesby[ind] * partial_sq) / dividetot\n",
    "        return qval, S_q_tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LocalPD:\n",
    "    def __init__(self, glass_atoms_list, center_atom, cutoff, dimension=1, weights=None, birch_threshold=0.075):\n",
    "        self.atom_list = glass_atoms_list\n",
    "        self.center_atom = center_atom\n",
    "        self.cutoff = cutoff\n",
    "        self.dimension = dimension\n",
    "        self.weights = weights\n",
    "        self.birch_threshold = birch_threshold\n",
    "\n",
    "    def compute_features(self):\n",
    "        sampling_centers = self.find_sampling_centers()\n",
    "        features = []\n",
    "        for atoms in self.atom_list:\n",
    "            peristence_diagrams = self.get_local_persistence(atoms, self.center_atom, self.cutoff)\n",
    "            features.append(self.kde_pd(sampling_centers, peristence_diagrams))\n",
    "        return np.vstack(features)\n",
    "\n",
    "    def center_atoms(self, atoms, center_atom):\n",
    "        dim = np.diagonal(atoms.get_cell())\n",
    "        positions = atoms.get_positions()\n",
    "        x_dif = positions[:, 0] -  positions[center_atom,0]\n",
    "        y_dif = positions[:, 1] -  positions[center_atom,1]\n",
    "        z_dif = positions[:, 2] -  positions[center_atom,2]\n",
    "        x_dif = np.where(x_dif > 0.5 * dim[0], positions[:, 0] - positions[center_atom, 0] - dim[0], x_dif)\n",
    "        y_dif = np.where(y_dif > 0.5 * dim[1], positions[:, 1] - positions[center_atom, 1] - dim[1], y_dif)\n",
    "        z_dif = np.where(z_dif > 0.5 * dim[2], positions[:, 2] - positions[center_atom, 2] - dim[2], z_dif)\n",
    "        x_dif = np.where(x_dif < -0.5 * dim[0], positions[:, 0] - positions[center_atom, 0] + dim[0], x_dif)\n",
    "        y_dif = np.where(y_dif < -0.5 * dim[1], positions[:, 1] - positions[center_atom, 1] + dim[1], y_dif)\n",
    "        z_dif = np.where(z_dif < -0.5 * dim[2], positions[:, 2] - positions[center_atom, 2] + dim[2], z_dif)\n",
    "        new_postions = np.vstack([x_dif,y_dif,z_dif]).T\n",
    "        return new_postions\n",
    "\n",
    "    def get_local_persistence(self, atom, center_id, cutoff):\n",
    "        persistence_diagrams = []\n",
    "        if isinstance(center_id, str):\n",
    "            types = atom.get_chemical_symbols()\n",
    "        if isinstance(center_id, int):\n",
    "            types = atom.get_atomic_numbers()\n",
    "        centers = np.where(np.array(types) == center_id)[0]\n",
    "        for i in tqdm(centers):\n",
    "            neighbors = np.where(atom.get_dist()[i, :] < cutoff)[0]\n",
    "            neighborhood = atom[neighbors]\n",
    "            center_index = np.where(neighbors == i)\n",
    "            neighborhood.set_positions(self.center_atoms(neighborhood,center_index))\n",
    "            persistence_diagrams.append(neighborhood.get_persistence_diagram(dimension=self.dimension, weights=self.weights))\n",
    "        return persistence_diagrams\n",
    "\n",
    "    def find_sampling_centers(self):\n",
    "        peristence_diagrams = self.get_local_persistence(self.atom_list[0], self.center_atom, self.cutoff)\n",
    "        total_df = pd.concat(peristence_diagrams)\n",
    "        birth_death = np.array([total_df['Birth'], total_df['Death'] - total_df['Birth']]).T\n",
    "        birch = Birch(n_clusters=100, threshold = self.birch_threshold).fit(birth_death)\n",
    "        return birch.subcluster_centers_\n",
    "\n",
    "    def kde_pd(self, centers, list_pds):\n",
    "        features = []\n",
    "        for pd in list_pds:\n",
    "            data = np.vstack((pd['Birth'], pd['Death'] - pd['Birth'])).T\n",
    "            kde = KernelDensity(kernel='gaussian', bandwidth=0.2).fit(data)\n",
    "            features.append(np.exp(kde.score_samples(centers)))\n",
    "        features = np.array(features)\n",
    "        return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m atoms \u001b[38;5;241m=\u001b[39m \u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/Users/rasmus/Library/CloudStorage/OneDrive-AalborgUniversitet/Ph.D. Projekt/sodium_silicate/30Na_800/data/114/propensity/27/md.lammpstrj\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m:\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlammps-dump-text\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m atoms \u001b[38;5;241m=\u001b[39m [glass_Atoms(atom) \u001b[38;5;28;01mfor\u001b[39;00m atom \u001b[38;5;129;01min\u001b[39;00m atoms]\n\u001b[1;32m      4\u001b[0m corr_atoms_dic \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m1\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNa\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m2\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mO\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m3\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSi\u001b[39m\u001b[38;5;124m'\u001b[39m}\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/pd_vis/lib/python3.10/site-packages/ase/io/formats.py:733\u001b[0m, in \u001b[0;36mread\u001b[0;34m(filename, index, format, parallel, do_not_split_by_at_sign, **kwargs)\u001b[0m\n\u001b[1;32m    731\u001b[0m io \u001b[38;5;241m=\u001b[39m get_ioformat(\u001b[38;5;28mformat\u001b[39m)\n\u001b[1;32m    732\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(index, (\u001b[38;5;28mslice\u001b[39m, \u001b[38;5;28mstr\u001b[39m)):\n\u001b[0;32m--> 733\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_iread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparallel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    734\u001b[0m \u001b[43m                       \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(_iread(filename, \u001b[38;5;28mslice\u001b[39m(index, \u001b[38;5;28;01mNone\u001b[39;00m), \u001b[38;5;28mformat\u001b[39m, io,\n\u001b[1;32m    737\u001b[0m                        parallel\u001b[38;5;241m=\u001b[39mparallel, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs))\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/pd_vis/lib/python3.10/site-packages/ase/parallel.py:275\u001b[0m, in \u001b[0;36mparallel_generator.<locals>.new_generator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(generator)\n\u001b[1;32m    270\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnew_generator\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    271\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (world\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m    272\u001b[0m         args \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(args[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mserial\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m    273\u001b[0m         \u001b[38;5;129;01mnot\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparallel\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m)):\n\u001b[1;32m    274\u001b[0m         \u001b[38;5;66;03m# Disable:\u001b[39;00m\n\u001b[0;32m--> 275\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m generator(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    276\u001b[0m             \u001b[38;5;28;01myield\u001b[39;00m result\n\u001b[1;32m    277\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/pd_vis/lib/python3.10/site-packages/ase/io/formats.py:803\u001b[0m, in \u001b[0;36m_iread\u001b[0;34m(filename, index, format, io, parallel, full_output, **kwargs)\u001b[0m\n\u001b[1;32m    801\u001b[0m \u001b[38;5;66;03m# Make sure fd is closed in case loop doesn't finish:\u001b[39;00m\n\u001b[1;32m    802\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 803\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m dct \u001b[38;5;129;01min\u001b[39;00m io\u001b[38;5;241m.\u001b[39mread(fd, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    804\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dct, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    805\u001b[0m             dct \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124matoms\u001b[39m\u001b[38;5;124m'\u001b[39m: dct}\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/pd_vis/lib/python3.10/site-packages/ase/io/formats.py:559\u001b[0m, in \u001b[0;36mwrap_read_function\u001b[0;34m(read, filename, index, **kwargs)\u001b[0m\n\u001b[1;32m    557\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m read(filename, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    558\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 559\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m atoms \u001b[38;5;129;01min\u001b[39;00m \u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    560\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m atoms\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/pd_vis/lib/python3.10/site-packages/ase/io/lammpsrun.py:316\u001b[0m, in \u001b[0;36mread_lammps_dump_text\u001b[0;34m(fileobj, index, **kwargs)\u001b[0m\n\u001b[1;32m    314\u001b[0m colnames \u001b[38;5;241m=\u001b[39m line\u001b[38;5;241m.\u001b[39msplit()[\u001b[38;5;241m2\u001b[39m:]\n\u001b[1;32m    315\u001b[0m datarows \u001b[38;5;241m=\u001b[39m [lines\u001b[38;5;241m.\u001b[39mpopleft() \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_atoms)]\n\u001b[0;32m--> 316\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloadtxt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdatarows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    317\u001b[0m out_atoms \u001b[38;5;241m=\u001b[39m lammps_data_to_ase_atoms(\n\u001b[1;32m    318\u001b[0m     data\u001b[38;5;241m=\u001b[39mdata,\n\u001b[1;32m    319\u001b[0m     colnames\u001b[38;5;241m=\u001b[39mcolnames,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    324\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    325\u001b[0m )\n\u001b[1;32m    326\u001b[0m images\u001b[38;5;241m.\u001b[39mappend(out_atoms)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/pd_vis/lib/python3.10/site-packages/numpy/lib/npyio.py:1318\u001b[0m, in \u001b[0;36mloadtxt\u001b[0;34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin, encoding, max_rows, quotechar, like)\u001b[0m\n\u001b[1;32m   1315\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(delimiter, \u001b[38;5;28mbytes\u001b[39m):\n\u001b[1;32m   1316\u001b[0m     delimiter \u001b[38;5;241m=\u001b[39m delimiter\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlatin1\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m-> 1318\u001b[0m arr \u001b[38;5;241m=\u001b[39m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcomment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcomment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdelimiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdelimiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1319\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconverters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconverters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskiplines\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskiprows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43musecols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43musecols\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1320\u001b[0m \u001b[43m            \u001b[49m\u001b[43munpack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munpack\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mndmin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mndmin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1321\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmax_rows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_rows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquote\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquotechar\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arr\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/pd_vis/lib/python3.10/site-packages/numpy/lib/npyio.py:1017\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(fname, delimiter, comment, quote, imaginary_unit, usecols, skiplines, max_rows, converters, ndmin, unpack, dtype, encoding)\u001b[0m\n\u001b[1;32m   1006\u001b[0m next_arr \u001b[38;5;241m=\u001b[39m _load_from_filelike(\n\u001b[1;32m   1007\u001b[0m     data, delimiter\u001b[38;5;241m=\u001b[39mdelimiter, comment\u001b[38;5;241m=\u001b[39mcomment, quote\u001b[38;5;241m=\u001b[39mquote,\n\u001b[1;32m   1008\u001b[0m     imaginary_unit\u001b[38;5;241m=\u001b[39mimaginary_unit,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     byte_converters\u001b[38;5;241m=\u001b[39mbyte_converters,\n\u001b[1;32m   1013\u001b[0m     c_byte_converters\u001b[38;5;241m=\u001b[39mc_byte_converters)\n\u001b[1;32m   1014\u001b[0m \u001b[38;5;66;03m# Cast here already.  We hope that this is better even for\u001b[39;00m\n\u001b[1;32m   1015\u001b[0m \u001b[38;5;66;03m# large files because the storage is more compact.  It could\u001b[39;00m\n\u001b[1;32m   1016\u001b[0m \u001b[38;5;66;03m# be adapted (in principle the concatenate could cast).\u001b[39;00m\n\u001b[0;32m-> 1017\u001b[0m chunks\u001b[38;5;241m.\u001b[39mappend(\u001b[43mnext_arr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mread_dtype_via_object_chunks\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1019\u001b[0m skiprows \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m  \u001b[38;5;66;03m# Only have to skip for first chunk\u001b[39;00m\n\u001b[1;32m   1020\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m max_rows \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "atoms = io.read(f\"/Users/rasmus/Library/CloudStorage/OneDrive-AalborgUniversitet/Ph.D. Projekt/sodium_silicate/30Na_800/data/114/propensity/27/md.lammpstrj\", index=':' , format=\"lammps-dump-text\")\n",
    "atoms = [glass_Atoms(atom) for atom in atoms]\n",
    "\n",
    "corr_atoms_dic = {1: 'Na', 2: 'O', 3:'Si'}\n",
    "for atom in atoms:\n",
    "    atom.set_new_chemical_symbols(corr_atoms_dic) \n",
    "atoms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [01:53<00:00,  5.29it/s]\n",
      "100%|██████████| 600/600 [01:53<00:00,  5.30it/s]\n",
      "100%|██████████| 600/600 [01:53<00:00,  5.30it/s]\n",
      "100%|██████████| 600/600 [01:53<00:00,  5.30it/s]\n",
      "100%|██████████| 600/600 [01:55<00:00,  5.21it/s]\n",
      "100%|██████████| 600/600 [01:54<00:00,  5.25it/s]\n",
      "100%|██████████| 600/600 [01:54<00:00,  5.22it/s]\n",
      "100%|██████████| 600/600 [01:54<00:00,  5.23it/s]\n",
      "100%|██████████| 600/600 [01:55<00:00,  5.21it/s]\n",
      "100%|██████████| 600/600 [01:56<00:00,  5.13it/s]\n"
     ]
    }
   ],
   "source": [
    "atoms_all = []\n",
    "\n",
    "for i in range(1,10,1):\n",
    "    obj = pd.read_pickle(f'/Volumes/My Passport for Mac/sodium silicate/dataset_800/30Na_{i}.pickle')\n",
    "    particle_type = obj[\"types\"]\n",
    "    type_dic = obj[\"type_dic\"]\n",
    "    symbols = list((pd.Series(particle_type.tolist())).map(type_dic))\n",
    "    pos = obj[\"start_positions\"]\n",
    "    cell = obj[\"box\"]\n",
    "    atoms = glass_Atoms(f'Si3000', positions=pos, cell=cell, pbc=True)\n",
    "    atoms.set_chemical_symbols(symbols)\n",
    "    atoms_all.append(atoms)\n",
    "\n",
    "LPD_features = LocalPD(atoms_all, 'Na', 5).compute_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [] \n",
    "\n",
    "for i in range(1,10,1):\n",
    "    obj = pd.read_pickle(f'/Volumes/My Passport for Mac/sodium silicate/dataset_800/30Na_{i}.pickle')\n",
    "    particle_type = obj[\"types\"]\n",
    "    type_dic = obj[\"type_dic\"]\n",
    "    symbols = list((pd.Series(particle_type.tolist())).map(type_dic))\n",
    "    Na_ind = np.where(np.array(symbols).flatten()==\"Na\")[0]\n",
    "    pos = obj[\"start_positions\"]\n",
    "    trajectory_target_positions = obj[\"target_positions\"]\n",
    "    targets = np.mean([np.linalg.norm(t - pos, axis=-1) for t in trajectory_target_positions], axis=1)\n",
    "    targets = targets[:,Na_ind]   \n",
    "    y.append(targets)\n",
    "\n",
    "y = np.array(y)\n",
    "ys = np.swapaxes(y,1,2)\n",
    "y_all = np.reshape(ys,(ys.shape[0]*ys.shape[1],ys.shape[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test error: 6.079265529158714e-05\n",
      "Pearson: 0.006473289019010621\n",
      "Test error: 0.03109773664132023\n",
      "Pearson: 0.12037554682142282\n",
      "Test error: 0.10397700758881764\n",
      "Pearson: 0.1489993123616825\n",
      "Test error: 0.38611189486922376\n",
      "Pearson: 0.20536715779676742\n",
      "Test error: 1.1717835995580177\n",
      "Pearson: 0.2990706221325103\n",
      "Test error: 1.9848251604037812\n",
      "Pearson: 0.31523415460844956\n",
      "Test error: 5.25117424227259\n",
      "Pearson: 0.3378245598243348\n",
      "Test error: 7.488413211068977\n",
      "Pearson: 0.34620277357278684\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 8 is out of bounds for axis 1 with size 8",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [117], line 19\u001b[0m\n\u001b[1;32m     17\u001b[0m pearson \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m9\u001b[39m,\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m---> 19\u001b[0m     x_train, x_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(LPD_features, \u001b[43my_all\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43mt\u001b[49m\u001b[43m]\u001b[49m, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.20\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m     20\u001b[0m     regr \u001b[38;5;241m=\u001b[39m m\n\u001b[1;32m     21\u001b[0m     regr\u001b[38;5;241m.\u001b[39mfit(x_train, y_train)\n",
      "\u001b[0;31mIndexError\u001b[0m: index 8 is out of bounds for axis 1 with size 8"
     ]
    }
   ],
   "source": [
    "def PearsonCC2(output, target):\n",
    "    x = output\n",
    "    y = target\n",
    "    vx = x - np.mean(x)\n",
    "    vy = y - np.mean(y)\n",
    "    cost = np.sum(vx * vy) / (np.sqrt(np.sum(vx ** 2)) * np.sqrt(np.sum(vy ** 2)))\n",
    "    return cost\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "m = GradientBoostingRegressor(random_state=0)\n",
    "m = LinearRegression()\n",
    "\n",
    "loss = []\n",
    "pearson = []\n",
    "for t in range(0,9,1):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(LPD_features, y_all[:,t], test_size=0.20, random_state=42)\n",
    "    regr = m\n",
    "    regr.fit(x_train, y_train)\n",
    "    y_pred = regr.predict(x_test)\n",
    "    MSE = mean_squared_error(y_test,y_pred)\n",
    "    Pearson_i = PearsonCC2(y_pred, y_test)\n",
    "    loss.append(MSE)\n",
    "    pearson.append(Pearson_i)\n",
    "    print(f\"Test error: {MSE}\")\n",
    "    print(f\"Pearson: {Pearson_i}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyg-m1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.-1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
